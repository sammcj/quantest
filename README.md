# quantest
LLM (v)RAM estimator for GGUF models from huggingface and ollama across various quantisation and context sizes
