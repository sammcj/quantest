# Quantest

**THIS IS A WORK IN PROGRESS - NOT YET FUNCTIONAL**

LLM (v)RAM estimator for GGUF models from huggingface and ollama across various quantisation and context sizes.

At present quantest is in the process of being used as a library in my [Gollama](https://github.com/sammcj/gollama) and [Ingest](https://github.com/sammcj/ingest) projects.
